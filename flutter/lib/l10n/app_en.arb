{
  "@@locale": "en",
  "share": "Share",
  "dontShare": "Don't Share",
  "privacyPrompt": "Would you like to share your anonymous and basic system information with MLCommons.org to help accelerate innovation?",
  "promptSubText": "By clicking share you agree to our ",
  "privacyPolicyButton": "privacy policy.",
  "unsupportedMainMessage": "This device is not yet supported.",
  "unsupportedBackendError": "Error message",
  "unsupportedTryAnotherDevice": "Please try the app on another device",
  "mainTitle": "Measure",
  "loadingContent": "Loading content...",
  "go": "GO",
  "measureCapability": "Measure your device performance for:",
  "measuring": "Measuring...",
  "dontCloseApp": "Don't close the app!",
  "cancel": "Cancel",
  "unverified": "Unverified",
  "resultsPerformanceTitle": "Results (qps)",
  "resultsAccuracyTitle": "Results",
  "performance": "Performance",
  "accuracy": "Accuracy",
  "detailedResults": "Detailed Results",
  "testAgain": "Test Again",
  "shareResults": "Share Results",
  "experimentResultsSubj": "Experiment results",
  "settingsTitle": "Settings",
  "configTitle": "Configuration",
  "resultsBatchSize": "Batches: <batchSize>",
  "configPreset": "Preset",
  "configPresetSubtitle": "Use preset for batch size and number of threads.",
  "sharing": "Sharing",
  "sharingSubtitle": "Share your anonymous results and basic system information.",
  "submissionMode": "Submission mode",
  "submissionModeSubtitle": "Switch on/off submission mode.",
  "offlineMode": "Offline mode",
  "offlineModeSubtitle": "In offline mode, a warning will be raised if the app tries to use internet resources.",
  "warningOfflineModeEnabled": "Offline mode is enabled but following internet resources are defined in the configuration. Do you want to continue?",
  "cooldown": "Cooldown",
  "cooldownSubtitle": "Pause <cooldownPause> minutes before running each benchmark to avoid thermal throttling.",
  "privacyPolicy": "Privacy policy",
  "eula": "End User License Agreement",
  "run": "Run",
  "taskConfigSettingsEntry": "Task configuration",
  "errorDialogTitle": "Errors",
  "successDialogTitle": "Success",
  "incorrectDatasetsPath": "Selected datasets directory does not contain files for following benchmarks:",
  "wrongChecksum": "The following files failed checksum validation:",
  "ok": "Ok",
  "waitBenchmarks": "Wait for benchmark to finish",
  "cooldownStatus": "Cooldown pause",
  "imageClassification": "Image Classification",
  "objectDetection": "Object detection",
  "imageSegmentation": "Image Segmentation",
  "languageProcessing": "Language Processing",
  "imageClassificationOffline": "Image Classification (offline)",
  "icInfo": "Image Classification",
  "odInfo": "Object detection",
  "isInfo": "Image Segmentation",
  "luInfo": "Language Processing",
  "internetResource": "downloadable",
  "localResource": "local",
  "errorConfig": "Path to config is invalid:",
  "notAvailableModel": "Model is not available",
  "settingsKeepLogs": "Keep logs",
  "settingsKeepLogsSubtitle": "Keep loadgen logs of future runs.\nThis option doesn't affect past logs.",
  "benchmarkType": "TFLite",
  "progressScreenNamePerformance": "<taskName>",
  "progressScreenNameAccuracy": "<taskName> (accuracy)",
  "progressScreenStage": "Stage progress: <percent>%",
  "unableSpecifyConfiguration": "Could not specify until benchmarks is running or content is loading",
  "icInfoDescription": "Image classification picks the best label to describe an input image and is commonly used for photo search and text extraction. The MobileNetEdgeTPU reference model is evaluated on the ImageNet 2012 validation dataset and requires 74.66% (98% of FP32 accuracy) Top-1 accuracy (app uses a different dataset).\n\nThe MobileNetEdgeTPU network is a descendent of the MobileNet-v2 family that is optimized for low-latency and mobile accelerators. The MobileNetEdgeTPU model architecture is based on convolutional layers with inverted residuals and linear bottlenecks, similar to MobileNet v2, but is optimized by introducing fused inverted bottleneck convolutions to improve hardware utilization, and removing hard-swish and squeeze-and-excite blocks.",
  "odInfoDescription": "Object detection draws bounding boxes around recognized objects in an input image, assigning each one a label. This is a common approach for identifying objects in photos, and automotive safety. The reference model is a Single Shot Detector based MobileDet model operating on the COCO 2017 validation dataset with a mean Average Precision (mAP) of 27.1 (95% of FP32 accuracy).\n\nMobileDet-SSD provides substantial improvements in the latency-accuracy trade-off by incorporating regular convolutions along with depthwise-separable convolutions in the search space for the object detection task, and effectively placing them in the network via neural architecture search (from: https://arxiv.org/pdf/2004.14525.pdf)",
  "isMosaicInfoDescription": "Semantic image segmentation divides an input image into labeled regions at pixel granularity (e.g., labeling all pixels associated with a car and labeling every pixel in the image), and is used for complex image scene parsing to power downstream image analysis and processing.\n\nThe reference model is the MOSAIC network, which was designed with current mobile processors and accelerators in mind, and uses a 512x512 input image resolution. The backbone feature extractor uses a modified version of MobileNet-v3.5-MultiHardware which was developed with Network Architecture Search (NAS) to optimize inference speed on various mobile processors and accelerators. Performance and accuracy are evaluated on the ADE20K validation dataset. The benchmark requires a mean Intersection Over Union (mIoU) value of 57.36% (96% of FP32 accuracy).\n\nMOSAIC uses an efficient multi-scale context encoder and a light-weight hybrid decoder to recover spatial details from aggregated information. MOSAIC produces state-of-the-art results balancing between model accuracy and speed across CPUs, GPUs, DSPs and NPUs.",
  "luInfoDescription": "Question Answering finds the  best answer to an input question based on a body of text. The reference model, MobileBERT, is evaluated on the Stanford Question Answering Dataset (SQUAD) v1.1 Dev and achieves an F1-score of 90.0.\n\nMobileBERT is a thin, mobile-optimized version of the larger BERT (BERT_LARGE) network, equipped with bottleneck structures and a carefully designed balance between self-attention and feed-forward networks. Like BERT, it is task-agnostic, applicable for a variety of downstream NLP tasks, but for MLPerf we use the variant fine-tuned for Q&A.",
  "clearCache": "Clear cache",
  "resourceErrorMessage": "Some resources failed to load.\nIf you didn't change config from default you can try clearing the cache.\nIf you use a custom configuration file ensure that it has correct structure or switch back to default config.",
  "resourceErrorSwitchToDefault": "Switch to default config",
  "resourceErrorCurrentConfig": "Current config file: ",
  "resourceErrorRereadConfig": "I have fixed current config, try again",
  "resourceErrorFail": "Config failed to load",
  "confirmClearCache": "All loaded resources will be deleted and downloaded again. Continue?",
  "confirmDialogTitle": "Confirm?",
  "uploadButton": "Upload results",
  "uploadSuccess": "Results uploaded successfully",
  "uploadFail": "Error uploading results",

  "notAvailable": "N/A",

  "historyListTitle": "Past results",
  "historyListElementSubtitle": "Average QPS <throughput> over <benchmarks#> benchmark(s)",

  "historyDetailsTitle": "Result details",
  "historyDetailsBuildTypeDebug": "debug build",
  "historyDetailsBuildTypeOfficial": "official",
  "historyDetailsBuildTypeUnofficial": "unofficial",
  "historyDetailsDate": "Date",
  "historyDetailsUUID": "UUID",
  "historyDetailsAvgQps": "Average throughput (QPS)",
  "historyDetailsAppVersion": "App version",
  "historyDetailsAppVersionTemplate": "<version> (build <build>) (<buildType>)",
  "historyDetailsBackendName": "Backend name",
  "historyDetailsTableTitle": "Benchmarks",
  "historyDetailsTableColName": "Benchmark name",
  "historyDetailsTableColPerf": "Throughput",
  "historyDetailsTableColAccuracy": "Accuracy",

  "historyRunDetailsTitle": "Run details",
  "historyRunDetailsBenchName": "Benchmark name",
  "historyRunDetailsScenario": "Scenario",
  "historyRunDetailsBackendName": "Backend name",
  "historyRunDetailsVendorName": "Vendor name",
  "historyRunDetailsAccelerator": "Accelerator",
  "historyRunDetailsBatchSize": "Batch size",
  "historyRunDetailsPerfTitle": "Performance run",
  "historyRunDetailsPerfQps": "Throughput",
  "historyRunDetailsValid": "Run is valid",
  "historyRunDetailsDuration": "Duration",
  "historyRunDetailsSamples": "Samples count",
  "historyRunDetailsDatasetType": "Dataset type",
  "historyRunDetailsDatasetName": "Dataset name",
  "historyRunDetailsAccuracyTitle": "Accuracy run",
  "historyRunDetailsAccuracy": "Accuracy",

  "historyValueCopiedToast": "<name> value copied to clipboard"
}

