{
  "@@locale": "en",
  "share": "Share",
  "dontShare": "Don't Share",
  "privacyPrompt": "Would you like to share your anonymous and basic system information with MLCommons.org to help accelerate innovation?",
  "promptSubText": "By clicking share you agree to our ",
  "privacyPolicyButton": "privacy policy.",
  "unsupportedMainMessage": "This device is not yet supported.",
  "unsupportedBackendError": "Error message",
  "unsupportedTryAnotherDevice": "Please try the app on another device",
  "mainTitle": "Measure",
  "loadingContent": "Loading content...",
  "go": "GO",
  "measureCapability": "Measure your device performance for:",
  "measuring": "Measuring...",
  "dontCloseApp": "Don't close the app!",
  "cancel": "Cancel",
  "unverified": "Unverified",
  "resultsPerformanceTitle": "Results (qps)",
  "resultsAccuracyTitle": "Results",
  "performance": "Performance",
  "accuracy": "Accuracy",
  "detailedResults": "Detailed Results",
  "testAgain": "Test Again",
  "shareResults": "Share Results",
  "experimentResultsSubj": "Experiment results",
  "settingsTitle": "Settings",
  "configTitle": "Configuration",
  "configBatchTitle": "Batch configuration",
  "configBatchSubtitle": "The product of batch size and number of threads must not exceed <maxValue>.",
  "configBatchSize": "Batch size: <batchSize>",
  "configBatchSizeSubtitle": "Set batch size value per thread. The maximum allowed number depends on the number of threads.",
  "configThreadsNumber": "Threads: <threadsNumber>",
  "configThreadsNumberSubtitle": "Set number of threads.",
  "resultsThreadsNumber": "Threads: <threadsNumber>",
  "resultsBatchSize": "Batches: <batchSize>",
  "configPreset": "Preset",
  "configPresetSubtitle": "Use preset for batch size and number of threads.",
  "sharing": "Sharing",
  "sharingSubtitle": "Share your anonymous results and basic system information.",
  "submissionMode": "Submission mode",
  "submissionModeSubtitle": "Switch on/off submission mode.",
  "offlineMode": "Offline mode",
  "offlineModeSubtitle": "In offline mode, a warning will be raised if the app tries to use internet resources.",
  "warningOfflineModeEnabled": "Offline mode is enabled but following internet resources are defined in the configuration. Do you want to continue?",
  "cooldown": "Cooldown",
  "cooldownSubtitle": "Pause <cooldownPause> minutes before running each benchmark to avoid thermal throttling.",
  "privacyPolicy": "Privacy policy",
  "eula": "End User License Agreement",
  "run": "Run",
  "benchmarksConfiguration": "Benchmarks configuration path",
  "benchmarksConfigurationTitle": "Benchmarks configuration",
  "errorDialogTitle": "Errors",
  "successDialogTitle": "Success",
  "incorrectDatasetsPath": "Selected datasets directory does not contain files for following benchmarks:",
  "ok": "Ok",
  "waitBenchmarks": "Wait for benchmark to finish",
  "cooldownStatus": "Cooldown pause",
  "imageClassification": "Image Classification",
  "objectDetection": "Object detection",
  "imageSegmentation": "Image Segmentation",
  "languageProcessing": "Language Processing",
  "imageClassificationOffline": "Image Classification (offline)",
  "icInfo": "Image Classification",
  "odInfo": "Object detection",
  "isInfo": "Image Segmentation",
  "luInfo": "Language Processing",
  "internetResource": "downloadable",
  "localResource": "local",
  "errorConfig": "Path to config is invalid:",
  "notAvailableModel": "Model is not available",
  "benchmarkType": "TFLite",
  "unableSpecifyConfiguration": "Could not specify until benchmarks is running or content is loading",
  "icInfoDescription": "Image classification picks the best label to describe an input image and is commonly used for photo search and text extraction. The MobileNetEdgeTPU reference model is evaluated on the ImageNet 2012 validation dataset and requires 74.66% (98% of FP32 accuracy) Top-1 accuracy (app uses a different dataset).\n\nThe MobileNetEdgeTPU network is a descendent of the MobileNet-v2 family that is optimized for low-latency and mobile accelerators. The MobileNetEdgeTPU model architecture is based on convolutional layers with inverted residuals and linear bottlenecks, similar to MobileNet v2, but is optimized by introducing fused inverted bottleneck convolutions to improve hardware utilization, and removing hard-swish and squeeze-and-excite blocks.",
  "odInfoDescription": "Object detection draws bounding boxes around recognized objects in an input image, assigning each one a label. This is a common approach for identifying objects in photos, and automotive safety. The reference model is a Single Shot Detector based MobileDet model operating on the COCO 2017 validation dataset with a mean Average Precision (mAP) of 27.1 (95% of FP32 accuracy).\n\nMobileDet-SSD provides substantial improvements in the latency-accuracy trade-off by incorporating regular convolutions along with depthwise-separable convolutions in the search space for the object detection task, and effectively placing them in the network via neural architecture search (from: https://arxiv.org/pdf/2004.14525.pdf)",
  "isInfoDescription": "Semantic image segmentation partitions an input image into labeled objects at pixel granularity, and is used for complex image manipulation such as red-eye reduction as well as automotive and medical applications. The reference model is theDeepLabv3+ network with a MobileNet-v2 feature extractor, using a 512x512 input image resolution. Performance and accuracy are evaluated on the ADE20K validation dataset. The benchmark requires a mean Intersection Over Union (mIoU) value of 53.156% (97% of FP32 accuracy).\n\nDeepLabV3+ uses an encoder-decoder architecture with atrous spatial pyramid pooling and a modular feature extractor. We selected MobileNet-V2 as the feature extractor, which enables state-of-the-art model accuracy within a constrained computational budget.",
  "luInfoDescription": "Question Answering finds the  best answer to an input question based on a body of text. The reference model, MobileBERT, is evaluated on the Stanford Question Answering Dataset (SQUAD) v1.1 Dev and achieves an F1-score of 90.0.\n\nMobileBERT is a thin, mobile-optimized version of the larger BERT (BERT_LARGE) network, equipped with bottleneck structures and a carefully designed balance between self-attensions and feed-forward networks. Like BERT, it is task-agnostic, applicable for a variety of downstream NLP tasks, but for MLPerf we use the variant fine-tuned for Q&A.",
  "clearCache": "Clear cache",
  "confirmClearCache": "All loaded resources will be deleted and downloaded again. Continue?",
  "confirmDialogTitle": "Confirm?",
  "uploadButton": "Upload results",
  "uploadSuccess": "Results uploaded successfully",
  "uploadFail": "Error uploading results"
}

