{
  "@@locale": "en",

  "unknown": "Unknown",
  "na": "N/A",

  "menuHome": "MLPerf Mobile",
  "menuHistory": "History",
  "menuSettings": "Settings",
  "menuAbout": "About",
  "menuProfile": "Profile",
  "menuSignIn": "Sign In",

  "userAnonymousUser": "Anonymous User",
  "userSignInAnonymously": "Sign in anonymously",
  "userSignedInAnonymously": "Signed in anonymously",
  "userSignInEmailPassword": "Sign in with email/password",
  "userProfile": "User Profile",
  "userId": "User ID",
  "userCreated": "Created",
  "userManageUploadedResults": "Manage uploaded results",
  "userUploadedFiles": "Uploaded Files",

  "unsupportedMainMessage": "This device is not yet supported.",
  "unsupportedBackendError": "Error message",
  "unsupportedTryAnotherDevice": "Please try the app on another device",

  "mainScreenLoading": "Loading Content",
  "mainScreenGo": "GO",
  "mainScreenMeasureTitle": "Measure your device performance for:",
  "mainScreenBenchmarkSelected": "Benchmarks (<selected>/<total> selected)",

  "progressPerformance": "Performance",
  "progressAccuracy": "Accuracy",
  "progressDontClose": "Don't close the app!",
  "progressCancel": "Cancel",
  "progressCooldown": "Cooldown Pause",
  "progressRemainingTime": "Remaining Time",
  "progressAborting": "Aborting",
  "progressWaiting": "Wait for current benchmark to finish!",

  "resultsTitleUnverified": "Unverified",
  "resultsTitlePerformance": "Results (qps)",
  "resultsTitleAccuracy": "Results",
  "resultsTabTitlePerformance": "Performance",
  "resultsTabTitleAccuracy": "Accuracy",
  "resultsDeleteConfirm": "Delete this results?",
  "resultsNotAvailable": "N/A",
  "resultsBenchmarkAborted": "Benchmark aborted!",
  "resultsBatchSize": "Batches: <batchSize>",

  "shareButtonMLCommons": "Share with MLCommons",
  "shareButtonOther": "Share with others",
  "shareButtonOtherSubject": "Benchmark result",

  "uploadSuccess": "Results uploaded successfully",
  "uploadFail": "Error uploading results",
  "uploadRequiredSignedIn": "An account is required to upload result.",
  "runFail": "Error while running benchmarks",

  "settingsOffline": "Offline mode",
  "settingsOfflineSubtitle": "In offline mode, a warning will be raised if the app tries to use internet resources.",
  "settingsRunMode": "Run mode",
  "settingsRunModeSubtitle": "Choose a benchmark run mode",
  "settingsArtificialCPULoadTitle": "Artificial CPU Load",
  "settingsArtificialCPULoadSubtitle": "Some devices perform better with an additional artificial CPU load during test",
  "settingsCrashlyticsTitle": "Crash reporting",
  "settingsCrashlyticsSubtitle": "Send crash log to MLCommons",
  "settingsKeepLogs": "Keep logs",
  "settingsKeepLogsSubtitle": "Keep loadgen logs of future runs.\nThis option doesn't affect past logs.",
  "settingsCooldown": "Cooldown",
  "settingsCooldownSubtitle": "Pause <cooldownPause> minutes before running each benchmark to avoid thermal throttling.",
  "settingsPrivacyPolicy": "Privacy Policy",
  "settingsEula": "End User License Agreement",
  "settingsTaskConfigTitle": "Task configuration",
  "settingsTaskConfigInternetResource": "downloadable",
  "settingsTaskConfigLocalResource": "local",
  "settingsTaskConfigError": "Path to config is invalid:",
  "settingsTaskDataFolderTitle": "Data folder",
  "settingsClearCache": "Clear cache",
  "settingsClearCacheConfirm": "All loaded resources will be deleted and downloaded again. Continue?",
  "settingsUnableSpecifyConfiguration": "Could not specify until benchmarks is running or content is loading",

  "dialogTitleWarning": "Warning",
  "dialogTitleError": "Error",
  "dialogTitleSuccess": "Success",
  "dialogOk": "Ok",
  "dialogCancel": "Cancel",
  "dialogTitleConfirm": "Confirm?",
  "dialogContentOfflineWarning": "Offline mode is enabled but following internet resources are defined in the configuration. Do you want to continue?",
  "dialogContentMissingFiles": "The following files don't exist:",
  "dialogContentChecksumError": "The following files failed checksum validation:",
  "dialogContentNoSelectedBenchmarkError": "Please select at least one benchmark.",


  "benchModePerformanceOnly": "Performance Only",
  "benchModeAccuracyOnly": "Accuracy Only",
  "benchModeSubmissionRun": "Submission Run",
  "benchNameImageClassification": "Image Classification",
  "benchNameObjectDetection": "Object detection",
  "benchNameImageSegmentation": "Image Segmentation",
  "benchNameLanguageProcessing": "Language Processing",
  "benchNameImageClassificationOffline": "Image Classification (offline)",
  "benchNameSuperResolution": "Super Resolution",
  "benchNameStableDiffusion": "Stable Diffusion",
  "benchInfoImageClassification": "Image Classification",
  "benchInfoObjectDetection": "Object detection",
  "benchInfoImageSegmentation": "Image Segmentation",
  "benchInfoLanguageProcessing": "Language Processing",
  "benchInfoSuperResolution": "Super Resolution",
  "benchInfoStableDiffusion": "Stable Diffusion",
  "benchInfoImageClassificationDesc": "Image classification picks the best label to describe an input image and is commonly used for photo search and text extraction. The MobileNetEdgeTPU reference model is evaluated on the ImageNet 2012 validation dataset and requires a minimum accuracy of 74.66% (98% of FP32 accuracy of 76.19%) Top-1 accuracy (For Performance measurements, App uses a different dataset).\n\nThe MobileNetEdgeTPU network is a descendent of the MobileNet-v2 family that is optimized for low-latency and mobile accelerators. The MobileNetEdgeTPU model architecture is based on convolutional layers with inverted residuals and linear bottlenecks, similar to MobileNet v2, but is optimized by introducing fused inverted bottleneck convolutions to improve hardware utilization, and removing hard-swish and squeeze-and-excite blocks.\n\nThe offline variant of image classification has no latency constraints and typically uses batched inference and has higher throughput.",
  "benchInfoImageClassificationV2Desc": "Image classification picks the best label to describe an input image and is commonly used for photo search and text extraction.\n\nThe MobileNetV4-Conv-L model boasts an impressive 83% accuracy with the ImageNet dataset, versus 76% accuracy for the prior standard, MobileNetEdgeTPU. MobileNetV4-Conv-L is designed to perform well across a range of mobile processor types, from CPUs and GPUs to neural accelerators. The MLPerf Mobile working group worked closely with the MobileNetV4 team in order to ensure optimized performance. This combination of an improved model architecture and collaborative optimization has proven quite potent. Although MobileNetV4-Conv-L executes six times the number of mathematical operations of its predecessor, MobileNetEdgeTPU, benchmark execution times have only increased by a factor of roughly 4.6.\n\nThe offline variant of image classification has no latency constraints and typically uses batched inference and has higher throughput.",
  "benchInfoObjectDetectionDesc": "Object detection draws bounding boxes around recognized objects in an input image, assigning each one a label. This is a common approach for identifying objects in photos, and automotive safety. Since v1.0, our reference model has been updated to MobileDets (from v0.7 model,  Single Shot Detector with a MobileNet-v2 feature extractor operating). MobileDets are trained on the COCO 2017 validation dataset. The MobileDets Object Detection task is evaluated on the COCO 2017 dataset with an input image resolution of 320x320. It requires a minimum  mean Average Precision (mAP) of 27.075 (95% of FP32 mAP of 28.5%), which is significantly higher than that of the previous model.\n\nMobileDets are searched for object detection. A key feature of MobileDets is that the search space includes both inverted bottleneck blocks and regular convolution operations to help improve the accuracy-latency trade-off on several hardware accelerators.",
  "benchInfoImageSegmentationDesc": "Semantic image segmentation partitions an input image into labeled objects at pixel granularity, and is used for complex image manipulation such as red-eye reduction as well as automotive and medical applications. The reference model is the MOSAIC network paired with a tailored feature extraction backbone. It operates on 512x512 resolution input images from the ADE20K validation set and requires a minimum mean Intersection Over Union (mIoU) value of 57.36% (96% of FP32 mIoU of 59.75%), significantly higher than the previous segmentation model (MobileNetv2-Deeplabv3+).\n\nMOSAIC employs a simple asymmetric encoder-decoder structure which consists of an efficient multi-scale context encoder and a light-weight hybrid decoder to recover spatial details from aggregated information with multiple lateral connections between the two. The feature extractor is a variant of MobileNet Multi-Hardware, which is a network built and optimized with neural architecture search. It is further enhanced for image segmentation by reducing the output stride, adding dilated convolutions at the end stage, and halving the feature channels.",
  "benchInfoLanguageProcessingDesc": "Question Answering finds the best answer to an input question based on a body of text, and is commonly employed in applications such as virtual assistants and chatbots. The reference model, MobileBERT, is evaluated on the Stanford Question Answering Dataset (SQUAD) v1.1 Dev-mini. The task requires a minimum F1-score of 87.4% (93% of FP32 F1-score of 93.08%).\n\nMobileBERT is a streamlined, mobile-optimized version of the larger BERT_LARGE network. It features bottleneck structures and a carefully designed balance between self-attention and feed-forward networks. While BERT is task-agnostic and can be applied to various downstream natural language processing tasks, the MobileBERT variant used in MLPerf is specifically fine-tuned for question answering.",
  "benchInfoSuperResolutionDesc": "Image Super Resolution (SR) upscales a lower resolution input into a higher resolution output image, enhancing the quality and detail. It is a common task in many mobile applications such as digital zoom. The reference model, EDSR F32B5, is a lightweight member of the Enhanced Deep Super Resolution (EDSR) family that is trained for 2X super resolution on the DIV2K dataset with bicubic downsampling and tested on the OpenSR test-set which comprises 25 selected 1920x1080 HDR images. The benchmark requires a minimum accuracy of 33 dB Peak Signal to Noise Ratio (PSNR) relative to a 33.58 dB accuracy with FP32.\n\nThe EDSR family of models demonstrated excellent performance by winning a super resolution challenge at CVPR 2017. The EDSR F32B5 reference model features five EDSR blocks, each with 32 feature maps. The EDSR block is a simple residual block consisting of a residual connection on one branch and a convolution-ReLU-convolution on the other branch. The final upsampling layer is a depth-to-space operator, which facilitates the x2 super resolution process.",
  "benchInfoStableDiffusionDesc": "The Text to Image Gen AI benchmark adopts Stable Diffusion v1.5 for generating images from text prompts. It is a latent diffusion model. The benchmarked Stable Diffusion v1.5 refers to a specific configuration of the model architecture that uses a downsampling-factor 8 autoencoder with an 860M UNet,123M CLIP ViT-L/14 text encoder for the diffusion model, and VAE Decoder of 49.5M parameters. The model was trained on 595k steps at resolution of 512x512, which enables it to generate high quality images. We refer you to https://huggingface.co/benjamin-paine/stable-diffusion-v1-5 for more information. The benchmark runs 20 denoising steps for inference, and uses a precalculated time embedding of size 1x1280. Reference models can be found here https://github.com/mlcommons/mobile_open/releases.\n\nFor latency benchmarking, we benchmark end to end, excluding the time embedding calculation and the tokenizer. For accuracy calculations, the app adopts the CLIP metric for text-to-image consistency, and further evaluation of the generated images using this Image Quality Aesthetic Assessment metric https://github.com/idealo/image-quality-assessment/tree/master?tab=readme-ov-file",

  "resourceErrorMessage": "Some resources failed to load.\nIf you didn't change config from default you can try clearing the cache.\nIf you use a custom configuration file ensure that it has correct structure or switch back to default config.",
  "resourceErrorSelectTaskFile": "Update task configuration",
  "resourceErrorCurrentConfig": "Current task config file: ",
  "resourceErrorRereadConfig": "I have fixed current config, try again",
  "resourceErrorFail": "Config failed to load",

  "listScreenTitleMain": "Results",
  "listScreenTitleLocal": "Local",
  "listScreenTitleOnline": "Online",
  "listScreenOnlineDisabled": "Online results are unavailable",
  "listScreenNoResultsFound": "No results found",

  "historyListSelectionCancel": "Cancel",
  "historyListSelectionEnable": "Enable selection",
  "historyListSelectionSelectAll": "Select all",
  "historyListSelectionDeselect": "Clear selection",
  "historyListSelectionDelete": "Delete",
  "historyListSelectionDeleteConfirm": "Delete selected items?",

  "historyFilterTitle": "Filters",
  "historyFilterClear": "Clear Filters",
  "historyFilterApply": "Apply Filters",
  "historyFilterCreationDate": "Creation Date",
  "historyFilterPlatform": "Platform",
  "historyFilterBenchmarkID": "Benchmark ID",
  "historyFilterBackendID": "Backend ID",
  "historyFilterDeviceModel": "Device Model",
  "historyFilterManufacturer": "Manufacturer",
  "historyFilterSoC": "SoC",
  "historySortByDate": "Date",

  "historyDetailsTitle": "Result details",
  "historyDetailsBuildTypeDebug": "debug build",
  "historyDetailsBuildTypeOfficial": "official",
  "historyDetailsBuildTypeUnofficial": "unofficial",
  "historyDetailsDate": "Date",
  "historyDetailsUUID": "UUID",
  "historyDetailsAvgQps": "Average throughput (QPS)",
  "historyDetailsAppVersion": "App version",
  "historyDetailsAppVersionTemplate": "<version> (build <build>) (<buildType>)",
  "historyDetailsModelName": "Device model name",
  "historyDetailsSocName": "Device SoC/CPU name",
  "historyDetailsBackendName": "Backend name",
  "historyDetailsTableTitle": "Benchmarks",
  "historyDetailsTableColName": "Benchmark name",
  "historyDetailsTableColPerf": "Throughput",
  "historyDetailsTableColAccuracy": "Accuracy",
  "historyDetailsDeleteConfirm": "Delete this result?",
  "historyDetailsDelete": "Delete",

  "historyRunDetailsTitle": "Run details",
  "historyRunDetailsBenchName": "Benchmark name",
  "historyRunDetailsScenario": "Scenario",
  "historyRunDetailsBackendName": "Backend name",
  "historyRunDetailsVendorName": "Vendor name",
  "historyRunDetailsAccelerator": "Accelerator",
  "historyRunDetailsDelegate": "Delegate",
  "historyRunDetailsBatchSize": "Batch size",
  "historyRunDetailsPerfTitle": "Performance run",
  "historyRunDetailsPerfQps": "Throughput",
  "historyRunDetailsValid": "Run is valid",
  "historyRunDetailsDuration": "Duration",
  "historyRunDetailsSamples": "Samples count",
  "historyRunDetailsDatasetType": "Dataset type",
  "historyRunDetailsDatasetName": "Dataset name",
  "historyRunDetailsAccuracyTitle": "Accuracy run",
  "historyRunDetailsAccuracy": "Accuracy",

  "historyValueCopiedToast": "<name> value copied to clipboard"
}

